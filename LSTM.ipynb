{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Importing Libraries"
      ],
      "metadata": {
        "id": "CZbqA9YR0vIv"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbtCuF_TvjcM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import re\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "from sklearn.metrics import classification_report\n",
        "from textblob import TextBlob"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Download necessary NLTK data\n"
      ],
      "metadata": {
        "id": "KiE6Xjf80yfp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L2beOokcwyqJ",
        "outputId": "70cd9cb4-cfae-434a-d8bc-3f3add4fae33"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load built-in IMDB dataset from TensorFlow"
      ],
      "metadata": {
        "id": "gFgJaXBH00_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "imdb = tf.keras.datasets.imdb\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=5000)"
      ],
      "metadata": {
        "id": "RlR-iXbFzH1Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Word Index\n"
      ],
      "metadata": {
        "id": "akqV0d1h0213"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "word_index = imdb.get_word_index()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Src5NFa1zjar",
        "outputId": "ff85e0a7-7acc-4585-9894-1ff2b2dda456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/imdb_word_index.json\n",
            "\u001b[1m1641221/1641221\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocessing: Decode the reviews back into text (for TextBlob)"
      ],
      "metadata": {
        "id": "CWx7dLRH04y1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reverse_word_index = {value: key for key, value in word_index.items()}"
      ],
      "metadata": {
        "id": "6rF2-QOJzj2z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def decode_review(text):\n",
        "    return ' '.join([reverse_word_index.get(i - 3, '?') for i in text])"
      ],
      "metadata": {
        "id": "XQUeOJ8rzsEv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Preprocess Dataset for LSTM"
      ],
      "metadata": {
        "id": "RD41_lqt08Eq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocess Dataset for LSTM\n",
        "stop_words = set(stopwords.words('english'))\n",
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def preprocess_text(text):\n",
        "    text = re.sub(r'[^a-zA-Z]', ' ', text)\n",
        "    text = text.lower()\n",
        "    text = text.split()\n",
        "    text = [lemmatizer.lemmatize(word) for word in text if word not in stop_words]\n",
        "    return ' '.join(text)"
      ],
      "metadata": {
        "id": "Wdob7EHB0FCZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Decode and preprocess X_train and X_test for TextBlob"
      ],
      "metadata": {
        "id": "tni9CCh10_dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_text = [' '.join([reverse_word_index.get(i - 3, '?') for i in text]) for text in X_train]\n",
        "X_test_text = [' '.join([reverse_word_index.get(i - 3, '?') for i in text]) for text in X_test]"
      ],
      "metadata": {
        "id": "1OMtMwxA0GuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Padding the sequences for LSTM model"
      ],
      "metadata": {
        "id": "w8Mgai_91Cgk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = pad_sequences(X_train, maxlen=100)\n",
        "X_test = pad_sequences(X_test, maxlen=100)"
      ],
      "metadata": {
        "id": "CynT4EqE1FSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Model"
      ],
      "metadata": {
        "id": "vQLB4Yzo1H_i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
        "model.add(LSTM(units=128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CBKfknBa0I74",
        "outputId": "3a89bd9b-3334-479f-a8f9-89ba8c5d9bf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train Model"
      ],
      "metadata": {
        "id": "QzmPvpv71LYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_test, y_test), callbacks=[EarlyStopping(monitor='val_loss', patience=2)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F6C1WvGn0KvL",
        "outputId": "b11ed5e2-1b9e-42df-e67c-199396d8be23"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m204s\u001b[0m 514ms/step - accuracy: 0.7074 - loss: 0.5449 - val_accuracy: 0.8045 - val_loss: 0.4307\n",
            "Epoch 2/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m165s\u001b[0m 419ms/step - accuracy: 0.8511 - loss: 0.3480 - val_accuracy: 0.8343 - val_loss: 0.3865\n",
            "Epoch 3/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m178s\u001b[0m 357ms/step - accuracy: 0.8766 - loss: 0.3009 - val_accuracy: 0.8327 - val_loss: 0.3980\n",
            "Epoch 4/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m143s\u001b[0m 358ms/step - accuracy: 0.8871 - loss: 0.2690 - val_accuracy: 0.8439 - val_loss: 0.3615\n",
            "Epoch 5/5\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 342ms/step - accuracy: 0.9040 - loss: 0.2364 - val_accuracy: 0.8437 - val_loss: 0.3991\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Model"
      ],
      "metadata": {
        "id": "aRXQn6IC1OhM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred = (model.predict(X_test) > 0.5).astype(\"int32\")\n",
        "print(\"LSTM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdQyGURx0NDq",
        "outputId": "f8775dcb-7bfb-4a66-f6a1-7afe16165ca8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 60ms/step\n",
            "LSTM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85     12500\n",
            "           1       0.86      0.82      0.84     12500\n",
            "\n",
            "    accuracy                           0.84     25000\n",
            "   macro avg       0.84      0.84      0.84     25000\n",
            "weighted avg       0.84      0.84      0.84     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# LSTM Hyperparameter Tuning (changing dropout rates and layers)"
      ],
      "metadata": {
        "id": "vtNlaC1P1Qxq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_tuned = Sequential()\n",
        "model_tuned.add(Embedding(input_dim=5000, output_dim=128, input_length=100))\n",
        "model_tuned.add(LSTM(units=128, return_sequences=True))\n",
        "model_tuned.add(Dropout(0.4))\n",
        "model_tuned.add(LSTM(units=64))\n",
        "model_tuned.add(Dropout(0.3))\n",
        "model_tuned.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "model_tuned.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "history_tuned = model_tuned.fit(X_train, y_train, epochs=7, batch_size=64, validation_data=(X_test, y_test), callbacks=[EarlyStopping(monitor='val_loss', patience=2)])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wSQ7Dn-K0PU2",
        "outputId": "f59fa843-9142-4497-fcf5-83233a9885d6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/core/embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 608ms/step - accuracy: 0.7151 - loss: 0.5278 - val_accuracy: 0.8434 - val_loss: 0.3548\n",
            "Epoch 2/7\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m251s\u001b[0m 581ms/step - accuracy: 0.8779 - loss: 0.2986 - val_accuracy: 0.8489 - val_loss: 0.3431\n",
            "Epoch 3/7\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 496ms/step - accuracy: 0.9054 - loss: 0.2398 - val_accuracy: 0.8403 - val_loss: 0.3755\n",
            "Epoch 4/7\n",
            "\u001b[1m391/391\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m229s\u001b[0m 586ms/step - accuracy: 0.9226 - loss: 0.1932 - val_accuracy: 0.8458 - val_loss: 0.4137\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate Tuned Model"
      ],
      "metadata": {
        "id": "oSozqvat1T1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred_tuned = (model_tuned.predict(X_test) > 0.5).astype(\"int32\")\n",
        "print(\"Tuned LSTM Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_tuned))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-UbomnG40TLk",
        "outputId": "a4c6b469-278f-4f69-ce5f-5349e5ad2a39"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m782/782\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 82ms/step\n",
            "Tuned LSTM Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.87      0.85     12500\n",
            "           1       0.87      0.82      0.84     12500\n",
            "\n",
            "    accuracy                           0.85     25000\n",
            "   macro avg       0.85      0.85      0.85     25000\n",
            "weighted avg       0.85      0.85      0.85     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Compare LSTM with TextBlob"
      ],
      "metadata": {
        "id": "O5TyXwfG1V1C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def textblob_sentiment(text):\n",
        "    analysis = TextBlob(text)\n",
        "    return 1 if analysis.sentiment.polarity >= 0 else 0\n",
        "\n",
        "df_test = pd.DataFrame(X_test_text, columns=['review'])\n",
        "df_test['textblob_prediction'] = df_test['review'].apply(textblob_sentiment)\n",
        "\n",
        "print(\"TextBlob Classification Report:\")\n",
        "print(classification_report(y_test, df_test['textblob_prediction']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k42qU5QY0Usq",
        "outputId": "6d67bcdb-0899-4e39-d0b5-30bfc1c35aad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TextBlob Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.43      0.58     12500\n",
            "           1       0.63      0.95      0.76     12500\n",
            "\n",
            "    accuracy                           0.69     25000\n",
            "   macro avg       0.76      0.69      0.67     25000\n",
            "weighted avg       0.76      0.69      0.67     25000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Applications of Sentiment Analysis:\n",
        "1. **Product and service reviews**: Monitoring customer reviews and feedback.\n",
        "2. **Market research**: Analyzing trends and public opinion on products or events.\n",
        "3. **Social media monitoring**: Detecting public sentiment on platforms like Twitter.\n",
        "4. **Customer service**: Understanding customer satisfaction and areas for improvement.\n",
        "\n",
        "### Challenges in Sentiment Analysis:\n",
        "1. **Sarcasm and irony**: Hard for models to detect such subtleties.\n",
        "2. **Contextual interpretation**: Words may have different meanings depending on context.\n",
        "3. **Ambiguity in neutral statements**: Hard to classify whether neutral statements contain any sentiment.\n",
        "4. **Language nuances**: Variations in slang, idioms, and dialects can lead to inaccuracies."
      ],
      "metadata": {
        "id": "o0U-mtmr0pOz"
      }
    }
  ]
}